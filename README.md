# -Visual-Control-of-a-Quasi-Static-Robot

 Este proyecto se centra en la simulación de un brazo robótico de 6 grados de libertad
 controlado mediante gestos de la mano, utilizando tecnologías de visión por computadora
 como OpenCV y MediaPipe en Python y renderizamos en Processsing el brazo robótico en
 un entorno 3D. A través de una cámara web, los movimientos y las interacciones del brazo
 robótico se determinan mediante posición y gestos de la mano detectados en tiempo real.
 El brazo robótico puede moverse en respuesta a gestos, como "pulgar arriba" y "pulgar
 abajo", y es capaz de detectar y responder a la presencia de un cubo en la escena. La
 comunicación entre el cliente (Python) y el servidor (Processing) se realiza mediante
 TCP/IP.
